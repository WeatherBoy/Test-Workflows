\section{Analysis}
In the analysis, I will mostly cover the interviews I performed and the resulting insights. Firstly, I'll go over the answers I got from the single individual, with whom I went through all eight questionnaires. 

\subsection{The questionnaire responses}
The answers themselves aren't all that interesting on their own. Without "de-anonymising" the participant too greatly, I can briefly add that they have lived with type 1 diabetes for over thirty years, and as such, they have built strong habits. Therefore, their day-to-day isn't vastly negatively affected by the disease. Also, as alluded to by the comment to the B2-6 question of the B2 - Emotional Distress questionnaire\footnote{Which can be seen in appendix \autoref{sec:B2-emotional-distress-answers}.}, they are instead grateful that it can be "fixed" to such a strong degree and that they still get to live their life the way they want.
\\
However, after roughly an hour of interview and going through every question, I was definitely left with greater insight. First and foremost, answering all the questions in one sitting, in a row, was definitely never the intended way. As it is also stated in the DiaFocus report, the D1 (Food Behaviour), D2 (Pittsburgh Sleep Quality Index (PSQI) ), D3 (Hospital Anxiety and Depression Scale (HADS) ) and D4 questionnaires were issued based on what the patient themselves found to be important areas of concern (as answered by the C - Areas of Concern questionnaire). Additionally, the B1 - Life Style Information questionnaire would only be answered initially. After an initial consultation with a GP, the patient was then expected to answer the B2 - Emotional Distress and B3 - Well-Being (WHO-5) continuously, as in, on a weekly, bi-weekly or monthly basis, alongside the agreed-upon, between patient and GP, selection of D1, D2, D3 and D4.
\\
In \autoref{fig:diafocus-questionnaire-flow} can be seen the intended flow of the questionnaires as per the DiaFocus project~\cite{DiaFocus}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\textwidth]{figures/analysis/diafocus_questionnaire_flow.png}
    \caption{DiaFocus questionnaire flow.}
    \medskip
    \small
    \raggedright
    Description from the DiaFocus report: "The flow of questionnaires in DiaFocus starts from when the user installs the app, signs in, and starts using the application.". The image is taken from ~\cite{DiaFocus}.
    \label{fig:diafocus-questionnaire-flow}
\end{figure}

\noindent
As for the B4 - Diet \& Exercise and B5 - Blood Glucose, these were intended to be sampled in cooperation with the patient's mobile OS for the DiaFocus application, or in the case of B5, manually filled in, if the patient doesn't have an insulin pump. This is also why both of these quite important data points are lacking from my final HTML report.
\\
\\
For full transparency, I altered the setup a bit for the HADS and WHO-5 questionnaires post the interview. Originally, I had made a carbon copy of the DiaFocus' instruments; however, according to the WHO documentation~\cite{WHO5}, a higher score indicates a better well-being. I then changed both the instrument of appendix \autoref{sec:who-5} and the answers of appendix \autoref{sec:who-5-answers} accordingly. Albeit, I completely understand the motive behind reversing the scores, as they would then be directly comparable with the results of the other questionnaires. I "solved" this by reversing the score of the WHO-5 for the HTML report. 
\\
For the HADS, the objective truth seems murky. Quite a lot of sources~\cite{Wiki-HADS, DiaFocus, HADS, HADS-StrokeEngine, HADS-2017, HADS-Danish} agree on there being a verified instrument called the Hospital Anxiety and Depression Scale, which has 14 questions, rated on a scale of $[0, 3]$, with questions split evenly between the areas of anxiety and depression. From the original work, Zigmond et al.~\cite{HADS}, one might infer that a higher numeric score indicates greater signs of anxiety and depression, based on their indicated cut-off points and the phrasing of the numeric value to phrase translation in the appendix. Regardless, this is never stated explicitly.  
\\
Additionally, from Zigmond et al.~\cite{HADS}, the instrument wasn't made with a single uniform translation for every question. Instead, almost every question had a unique numeric value to phrase translation. Combined with multiple sources~\cite{HADS-StrokeEngine, HADS-Danish}  stating that some of the questions were reverse scored, yet differing in the exact amount, this leaves a murky image.
\\
I elected to reverse the overall scoring of the HADS, post responses and even change the wording, such that it was more in line with a majority of sources~\cite{HADS, HADS-StrokeEngine, HADS-2017, HADS-Danish}. From my own intuition, and believing a handful would be flipped in score, I elected to choose that question four\footnote{"I can sit at ease and feel relaxed."} of the anxiety instrument, was flipped and that questions one\footnote{"I still enjoy the things I used to enjoy."}, 
two\footnote{"I can laugh and see the funny side of things."}, three\footnote{"I feel cheerful."}, and six\footnote{"I look forward with enjoyment to things."} and seven\footnote{"I can enjoy a good book or radio or TV program."} was flipped.
\\
This is how it has been scored for the final HTML report moving forward.
\\
\\
Finally, I would like to address why I have both the B2 and PAID instruments, as well as answers for both. In short, I was too quick when going through the DiaFocus report initially. I hadn't noticed that the B2 instrument presented in Appendix B~\cite{DiaFocus} was an exact copy of the PAID-6 presented in the clinical report of Appendix D~\cite{DiaFocus}. This mishap led me to ask the exact same questions twice during the interview. However, we went through the questionnaires in the same order as presented in the Appendix \autoref{sec:questionnaire-instruments}. Therefore, we went through the "B2 - Emotional Distress" very early, and after roughly 40 minutes, we went through the "Problem Areas in Diabetes". Both the participant and I noticed that the questions were very similar, and both expressed that we felt we had been over them before. However, I believe that, coupled with the fact that it was the last questionnaire, we went through them anyway.
\\
Now, why keep both? Why not just toss one and not mention it? I might have. Were it not for the fact that they are distinct. Despite having the exact same questions and the exact same answer scale, the participant was slightly more negatively inclined on the second go than they had been 40 minutes earlier. More precisely, for B2, all but the second question was rated $0$ out of $[0-4]$. The second question was rated a $1$. For PAID, only the fourth and fifth questions were rated as $0$, the remaining were now at a $1$.
\\
This is quite pseudo-scientific, but I mention this as one of the medical students I interviewed also noted that people tend to answer more negatively when continuously probed on matters which are usually associated with negative emotion.

\subsection{Testing the HTML report}
I interviewed a total of three medical students. I did this by, firstly, explaining to them the context in which it was intended to be used. They all had some idea, as I have consulted all of them previously on this project; however, they didn't know that the HTML report was designed with the intent of assisting a GP in consultation with a diabetes patient. Then, secondly, I asked them to, to the best of their abilities, think out loud when going through the report. I would like to note that I tried to give them as little help as possible in navigating the HTML report, as, after all, the intent was to assess the UX. Yet, I'm fully aware that as a close friend of each of these three medical students and as the designer of the HTML report, I am in no way, shape or form an unbiased interviewer. 
\\
After an initial go through, I went a bit more in-depth and asked them, "What did you like?", "What, if anything, did you think was missing?", "Would you use this if you were a GP who had a consultation with a diabetes patient?".
\\
In the following, I will firstly cover their individual initial thoughts, then I will go through an overall assessment and cover the comments they had in common. Furthermore, I will refer to them as "A", "B" and "C" alphabetically ordered by the order in which they were interviewed.

\subsubsection*{Interview with "A"}
When I interviewed "A", the HTML report was not yet in the state that can be seen in Appendix \autoref{sec:html-report-pdf}. Then it was an almost solely ChatGPT-generated prototype with hallucinated questions and responses. However, it still contained the primary questionnaire structure and the bar plot, which can be seen at the top of the HTML report. Then I tried to largely replicate the DiaFocus clinical report header, of which I believe the inspiration is still noticeable in the final HTML report. "A" noted that it seemed strange to include the phone number and email address for the patient. Consequently, I made an A and B version of the HTML report. The A-version has a very information-heavy header, and the B-version, which is the one in the Appendix, has only the most crucial information present. "A" noted that the "Next consultation" information element of the header seemed smart. As if it were "N/A" or maybe "Not planned", then it would be a good reminder that planning the next consultation would be a key aspect of the current consultation. Admittedly, although it might be a cool feature, I manually included it through a metadata.json file placed in the same directory as the response JSON (the one named "YYYY-MM-DD.json"). The structure might be the same for a production-ready system, but automatic updates would likely require an integration with the healthcare institution where the consultation was performed. Based on the experience from my thesis, this prospect seemed like a wild pipe dream. "A" also noted that they liked the feature where, if you click on a specific bar of the bar plot, you are linked down to the actual questionnaire responses related to the specific score indicated by the bar plot. Finally, they added that they figured a yearly update on the "B1 - Life Style" might be productive as it could inform the GP whether they were still smoking, had stopped or might have begun. However, we also discussed the possibility of dynamically tweaking the B1 questionnaire, such that questions like exercise were exempted if they had continuously provided fitness data to the underlying system through a cooperation with their mobile OS (the questionnaire the DiaFocus report refers to as "B4 - Diet \& Exercise").  

\subsubsection*{Interview with "B"}
When I interviewed "B", the HTML report was almost identical to that of the appendix. The only difference is that I, at the time, had a tough bug with regard to extracting the information correctly from the JSON files. Therefore, I had hardcoded 1-2 questions per questionnaire directly into Python. It was neither good code nor a complete HTML report, but it got the job done as a prototype. "B" was quite thorough on the subjects they found missing and elaborated in greater detail on the subjects which "A" and "C" might only have mentioned in parsing. In turn, they didn't have a plethora of additional comments. "B" noted that if they wanted to go over the questionnaire responses with the patient, then the HTML report gave a very nice overview. They also noted that if they, as a GP, were concerned as to their patient's health and probably would have asked the questions at a consultation regardless, then it seemed like a nice timesaver to have them asked beforehand. Finally, "B" noted that in the case that the patient doesn't have an insulin pump, then it would be valuable information to have that noted in the HTML report, as it heavily pertains to how well they are at regulating their own insulin levels.

\subsubsection*{Interview with "C"}
When I interviewed "C", the HTML report was identical to that of the appendix. With regards to the design "C" noted a lot of the same facets as "A" and "B" had pointed out. Yet, they also stated that they found it unrealistic that the average patient would answer so many questions in between consultations. However, if the data were to be present, then they figured it was a cute setup. As the only one, "C" mentioned that they would like the underlying system to catch or flag possible connections. E.g. they pointed out that if the patient had been reporting an increasingly worse sleep score but also gained a lot of weight and exercised less within the same period, then there could be a correlation. Instead of "C" themselves spending time on analysing and finding this correlation, they would like for the system to be able to selectively pinpoint some problems like this (if present, of course). This, however, would require the HTML report to support a temporal data setup, which it currently doesn't and which I will elaborate further on in a moment. Finally, "C" noted that, like a system for detecting correlations, they would like for certain questions to be flagged as 'critical'. In particular, they mentioned the "Cannot breathe comfortably" question of the PSQI, which she would find very alarming if scored poorly, even if the overall PSQI score might not be within a critical threshold. We, in turn, also both agreed that defining such critical questions would require a more in-depth analysis and clinical expertise.

\subsubsection*{General feedback - temporal data, examination results, other chronic illnesses \& polypharmacy}
All three of the medical students were in agreement that the current v.2b of the HTML report, as can be seen in Appendix \autoref{sec:html-report-pdf}, definitely couldn't serve as an alternative to "Sundhedsplatformen" (which I can't but agree with as well). "C" explicitly stated that this might be a tool they would consider using if they knew the patient had had troubles with their mental health, sleep and adhering to both prescribed medication and a diet. Yet, even still, "C" would only look at it if they had spare time, which they didn't find to be expected within the healthcare sector. However, all three of them also independently agreed that if temporal data, medical examination results and a list of both medications and possible other chronic illnesses were to be included, then this would prove a far more valuable tool.
\\
Temporal data would be in the form of 1) the ongoing results from the questionnaires, 2) the data gotten from the OS, e.g. the B4 from the "Continuous Assessment" section of \autoref{fig:diafocus-questionnaire-flow}, and 3) data gotten from external applications, such as the blood glucose measurements and perhaps data from a sleep app. This way, it would be possible to see a development, rather than the current setup, which solely provides a snapshot. 
\\
Examination results would be like journal entries, but for the necessary and crucial examinations regarding diabetes patients. These are the eye, heart, kidney and feet examinations, as noted by the Official Danish Medical Handbook (Lægehåndbogen)~\cite{SundhedDK-diabetes}, performed in order to spot any issues which commonly lead to long-term medical complications for diabetes patients. "B" noted that he assumed that "B" themselves would perform the eye and foot examinations during consultations, but regardless of whether prior examinations were present, "B" would like to have them included in the HTML report. 
\\
A list of other chronic illnesses and prescribed medications is probably quite self-explanatory; however, they would help in assisting in how to treat the diabetes patient. "C" noted that it would be especially nice if the system itself provided a feature whereby one could type in a medication and the system could give a warning if there was a clash with any other previously prescribed medications. Both "A", "B", and "C" also noted that a list of other chronic illnesses could help give the GP a better overview and maybe find a possible causality for any sudden developments in the temporal data.

\subsection{Putting it all together - A FHIR-based datamodel for the HTML report}
