\section{Discussion}
Throughout this report, I've tried my hand at many different topics, ranging from researching and initialising a FHIR-compatible data warehouse-esque prototype, to designing and implementing a standardised HTML report for clinical use, to conducting user experience (UX) interviews with medical students. These varied endeavours have led to a lot of insights in terms of technical feasibility, domain knowledge, as well as user experience. In this section, I will address some of the more questionable choices made throughout, in addition to discussing prospects for future work.

\subsection{Main discussion points}
\subsubsection*{Biased user feedback}
As previously stated, for this report, I was unable to acquire a source of clinical data and/or expertise. Therefore, I ultimately relied on being able to interview a handful of medical students. While these students were all very knowledgeable and forthcoming with their feedback, they were, after all, still students. As such, it would be na\"ive to assume that their clinical experience, and by extension, their feedback, is on par with that of seasoned medical practitioners. Furthermore, as I am close friends with each of these students and know them intimately, there is the obvious risk that they might have been inclined to give more positive feedback than they would have otherwise.
\\
Although the setting for testing and data collection was not ideal, I am certain that the provided feedback was nevertheless valuable. The domain knowledge gathered from the interviews showcased numerous points of improvement for the HTML report, in addition to validating the overall concept of a standardised report. However, for further development of the concept, testing with actual medical practitioners would be a top priority.

\subsubsection*{Choice of coding setup}
With regards to the choice of setting up the standardised information, or infographic, as an automatically generated HTML report, based on the questionnaire data in a JSON format, an obvious question might be: Why?
\\
Initially, I attempted to play around with Figma, as I have had some prior experience from a course at DTU. Yet, after roughly an afternoon's worth of tinkering, I was simply left frustrated, as I felt the base version of Figma didn't provide, or at least not in an intuitive manner, the functionality I required. I also considered using Microsoft's PowerPoint for creating a mockup of the infographic, as I have quite substantial experience with this software. Again, I toyed around with it for a handful of hours; however, being a programmer at heart, I was irked by the lack of automation. I had already spent a considerable amount of time writing the questionnaire responses down and couldn't be bothered to format them nicely within PowerPoint. Instead, I went for a more technical approach by compiling the data into a JSON format and writing a script to generate the HTML report automatically.
\\
Despite this by no means being the most seamless approach for intricate UX testing, I stand by my choice. The codebase serves as a solid foundation for further development, and while building it, I developed a far better relationship with HTML code through using Python's \texttt{Jinja2} templating engine. Whereas I had previously always looked at HTML code as a jumbled mess of gibberish, I now feel I have a novice understanding of how it works. Not to mention, the choice of HTML as the output format opens up a plethora of possibilities for further development, seeing as HTML is a very flexible format that can be rendered on virtually any device with a screen and a web browser.

\subsection{Future work}
\subsubsection*{Data retrieval from external applications}
In the DiaFocus project~\cite{DiaFocus}, they mention how uncollaborative they found the users' (diabetes patients) mobile OS to be. Although the report is from 2023, I doubt that much has changed since then. This brings about the question of how much data can be retrieved not only from the mobile OS itself, but rather external applications. Maybe the user has a fitness app that tracks their steps, heart rate, and sleep patterns. If this data could be retrieved and integrated into the report, it would provide a more comprehensive view of the patient's health and lifestyle. However, firstly it would be prudent to assess through research how much additional value this data would provide, as it would be a significant undertaking to implement such functionality. There would be privacy concerns to consider, as well as the technical challenge of integrating with various third-party applications. In turn, this would very much not be in the spirit of standardisation, seeing as there are countless fitness and health tracking apps available, each with their own data formats and APIs. However, if a few popular apps could be integrated, it might be worth the investment.

\subsubsection*{Summarise medical journals}
Whilst still trying to figure out how to best work on some of the standardisation and UX testing within the Danish healthcare sector, I sat down with one of the medical students I would later interview regarding the HTML report. They then had a laptop with access to "Sundhedsplatformen" (SP), with which the student and I went through some of the core functionalities and setup. They showed me how they would typically use SP to look up patient information, such as previous diagnoses, prescriptions, and lab results.
\\
There has been a great deal of commotion surrounding SP, and I have already been over this in my thesis; hence, I will simply discuss a feature that might be integrated atop SP, rather than a fundamental change. First and foremost, for legal purposes, I obviously have to declare that I was only presented mock data. Secondly, I have to admit, everything I had heard about SP made it seem way worse than when I got to look around on the platform myself. There was quite a lot of functionality. However, it seemed, from my friend, that the greatest issue presented by SP was that not everyone uses it. It is very common for hospitals in the Capital Region to use SP, but GPs might use their own tools, which means data isn't necessarily transferable from individual clinics to hospitals. In addition, there are simply a lot of regions which doesn't use SP as they have their own system and they consider it superior. The biggest potential we discussed, regarding SP, was to find a way to somehow summarise patient journals. The workflow for medical practitioners at the moment seems to be, preferably, to completely ignore SP and simply talk to the colleague who has had the latest contact with your patient, but if that isn't possible, then look at the latest journal entry, and if there have been a lot of entries, then pluck out a couple for deeper inspection. For this, we briefly discussed the proposition of some kind of Large Language Model (LLM) in combination with a stricter journaling standardisation, e.g., by the use of FHIR to create a summary of journal entries for the medical practitioner. 
\\
With neither a comprehensive theoretical preface nor a thorough analysis, I simply had a gut feeling that if the journals were to be standardised, say using FHIR, then they could be processed through a combination of an LLM and some rule-based system to create a summary of the most important points for the medical practitioner. Although it isn't directly related to creating a standardised report for clinical use, I find this an incredibly interesting avenue for future work. It would require a great deal of development, standardisation, testing, and, necessarily, collaboration with the healthcare sector, but I believe it has the potential to significantly improve on a very tedious and time-consuming task for medical practitioners